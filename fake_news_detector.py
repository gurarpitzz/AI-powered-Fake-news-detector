# -*- coding: utf-8 -*-
"""Fake News Detector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1745AsT_JcgXK2iffhRRpDDDiVgs_NDyp
"""

#Fake News Detector Programm will retrive data from the given dataset fetched by kaggle and then use deep leaning using libraries like pandas, matplotlib and sklearn to do the necceary analysis

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import re

fake = pd.read_csv("/Fake.csv")
true = pd.read_csv("/True.csv")

fake.head()

true.head()

true.shape

fake.shape

fake["label"] = 0
true["label"] = 1

true.head()

news=pd.concat([fake,true])
news

21417+23481

news.head()

news.tail()

news.isnull().sum()

"""#depicts data has no null vales"""

news.drop(['title','subject','date'],axis=1)

"""##Reshuffiling of Dataset as it was earlier organized"""

news= news.sample(frac=1)#reshuffle data

news.head()

news=news.drop(['title','subject','date'],axis=1)

news

"""##Removing Unneccisary urls,html tags, emojis, newline char etc and converting data to lowercase"""

def wordopt(text):
  #convert to lowercase
    text = text.lower()
  #remove urls
    text=re.sub(r'https?://\S+|www.\.\S+','',text)
  #remove html tags
    text=re.sub(r'<.*?>','',text)
  #remove emojis
    text=re.sub(r'[^\w\s]','',text)
    return text
  #remove digits
    text=re.sub(r'\d','',text)
  #remove newline character
    text=re.sub(r'\n',' ',text)
    return text

news['text']=news['text'].apply(wordopt)

news['text']

x=news['text']
y=news['label']

x #textual data about news

y #data in 0's and 1's depicting its fake or not

"""##Vectorizing and formulationg data so as to be easilt read bo LR model"""

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)

from sklearn.feature_extraction.text import TfidfVectorizer

vecorization= TfidfVectorizer()
xv_train=vecorization.fit_transform(x_train)
xv_test=vecorization.transform(x_test)

"""*note-> vectorizing text is a very crucial element in reading a dataset by a model as without it prediction cannot be possible"""

xv_test

xv_train

"""##Logistic regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report # Import classification_report

LR = LogisticRegression()
LR.fit(xv_train,y_train)

pred_lr=LR.predict(xv_test)

LR.score(xv_test, y_test)

print(classification_report(y_test, pred_lr))

"""### News input and output"""

def output_lable(n):
    if n == 0:
        return "Fake News"
    elif n == 1:
        return "Not A Fake News"

def manual_testing(news):
    testing_news = {"text":[news]}
    new_def_test = pd.DataFrame(testing_news)
    new_def_test["text"] = new_def_test["text"].apply(wordopt)
    new_x_test = new_def_test["text"]
    new_xv_test = vecorization.transform(new_x_test)
    pred_LR = LR.predict(new_xv_test)
    # Print the prediction inside the function to access pred_LR
    print("\n\nLogistic Regression Prediction: {}".format(output_lable(pred_LR[0])))


news = str(input())
manual_testing(news) #call the function